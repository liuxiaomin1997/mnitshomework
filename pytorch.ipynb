{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning framework and it's easy to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the mnist data, preprocess them and encapsulate them into dataloader form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "normalize = transforms.Normalize(mean=[.5], std=[.5])\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "# download and load the data\n",
    "train_dataset = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./mnist/', train=False, transform=transform, download=False)\n",
    "\n",
    "# encapsulate them into dataloader form\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the model, object function and optimizer that we use to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpelNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1,hidden_size2, num_classes):\n",
    "        super(SimpelNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1) \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "model = SimpelNet(28*28, 100,100, 10).to(device)\n",
    "\n",
    "\n",
    "\n",
    "# TODO:define loss function and optimiter\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.8) #比sgd多了一个momentum参数\n",
    "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, alpha=0.9)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can start to train and evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/468], Loss: 0.4900\n",
      "Epoch [1/10], Step [200/468], Loss: 0.3363\n",
      "Epoch [1/10], Step [300/468], Loss: 0.3171\n",
      "Epoch [1/10], Step [400/468], Loss: 0.2928\n",
      "Accuracy of the network on the test images: 92.40785256410257 %\n",
      "Epoch [2/10], Step [100/468], Loss: 0.2862\n",
      "Epoch [2/10], Step [200/468], Loss: 0.2734\n",
      "Epoch [2/10], Step [300/468], Loss: 0.2379\n",
      "Epoch [2/10], Step [400/468], Loss: 0.1573\n",
      "Accuracy of the network on the test images: 95.3525641025641 %\n",
      "Epoch [3/10], Step [100/468], Loss: 0.1918\n",
      "Epoch [3/10], Step [200/468], Loss: 0.2898\n",
      "Epoch [3/10], Step [300/468], Loss: 0.1567\n",
      "Epoch [3/10], Step [400/468], Loss: 0.0791\n",
      "Accuracy of the network on the test images: 96.70472756410257 %\n",
      "Epoch [4/10], Step [100/468], Loss: 0.0718\n",
      "Epoch [4/10], Step [200/468], Loss: 0.1112\n",
      "Epoch [4/10], Step [300/468], Loss: 0.0822\n",
      "Epoch [4/10], Step [400/468], Loss: 0.1764\n",
      "Accuracy of the network on the test images: 96.38421474358974 %\n",
      "Epoch [5/10], Step [100/468], Loss: 0.1278\n",
      "Epoch [5/10], Step [200/468], Loss: 0.0526\n",
      "Epoch [5/10], Step [300/468], Loss: 0.1136\n",
      "Epoch [5/10], Step [400/468], Loss: 0.0171\n",
      "Accuracy of the network on the test images: 97.20552884615384 %\n",
      "Epoch [6/10], Step [100/468], Loss: 0.0473\n",
      "Epoch [6/10], Step [200/468], Loss: 0.0897\n",
      "Epoch [6/10], Step [300/468], Loss: 0.0361\n",
      "Epoch [6/10], Step [400/468], Loss: 0.1419\n",
      "Accuracy of the network on the test images: 97.31570512820512 %\n",
      "Epoch [7/10], Step [100/468], Loss: 0.1844\n",
      "Epoch [7/10], Step [200/468], Loss: 0.0990\n",
      "Epoch [7/10], Step [300/468], Loss: 0.0940\n",
      "Epoch [7/10], Step [400/468], Loss: 0.1725\n",
      "Accuracy of the network on the test images: 97.44591346153847 %\n",
      "Epoch [8/10], Step [100/468], Loss: 0.1029\n",
      "Epoch [8/10], Step [200/468], Loss: 0.0534\n",
      "Epoch [8/10], Step [300/468], Loss: 0.0700\n",
      "Epoch [8/10], Step [400/468], Loss: 0.0444\n",
      "Accuracy of the network on the test images: 96.74479166666667 %\n",
      "Epoch [9/10], Step [100/468], Loss: 0.0315\n",
      "Epoch [9/10], Step [200/468], Loss: 0.0405\n",
      "Epoch [9/10], Step [300/468], Loss: 0.0122\n",
      "Epoch [9/10], Step [400/468], Loss: 0.0379\n",
      "Accuracy of the network on the test images: 97.45592948717949 %\n",
      "Epoch [10/10], Step [100/468], Loss: 0.0134\n",
      "Epoch [10/10], Step [200/468], Loss: 0.0363\n",
      "Epoch [10/10], Step [300/468], Loss: 0.0484\n",
      "Epoch [10/10], Step [400/468], Loss: 0.0538\n",
      "Accuracy of the network on the test images: 97.59615384615384 %\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向传播和计算loss\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 后向传播和调整参数\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 每100个batch打印一次数据\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, NUM_EPOCHS, i+1, total_step, loss.item()))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    # evaluate\n",
    "    # TODO:calculate the accuracy using traning and testing dataset\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    " \n",
    "  \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5:\n",
    "Please print the training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.59615384615384 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
